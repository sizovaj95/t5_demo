{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ebd192b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import common as com\n",
    "from torch.utils.data import DataLoader\n",
    "from IPython.display import Markdown, display\n",
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f85c888d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bf6a633",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"31_model_w_prefix_50_output.pt\"\n",
    "model_finetuned = torch.load(f\"models/{model_name}\")\n",
    "model_finetuned.eval();\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\", model_max_length=com.MAX_INPUT_LEN)\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "model_bare = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
    "model_bare.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48f9a2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_one_text(text: str, model) -> str:\n",
    "    text = \"summarize: \" + text\n",
    "    encoded = tokenizer(text, max_length=com.MAX_INPUT_LEN, pad_to_max_length=True,\n",
    "                                       truncation=True,\n",
    "                                       padding=\"max_length\", return_tensors=\"pt\")\n",
    "    pred_ids = model.generate(\n",
    "        input_ids=encoded.input_ids,\n",
    "        attention_mask=encoded.attention_mask,\n",
    "        max_length=com.MAX_OUTPUT_LEN)\n",
    "    pred_text = tokenizer.decode(pred_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "    return pred_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "142b5ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, test_data = com.load_and_maybe_split_data(com.TRAIN_FRACTION, com.RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "610bf94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_tuned = []\n",
    "predictions_bare = []\n",
    "targets = []\n",
    "texts = []\n",
    "for i, row in test_data.iterrows():\n",
    "    review = row['review']\n",
    "    summary = row['summary']\n",
    "    \n",
    "    fine_tuned_summary = summarize_one_text(review, model_finetuned)\n",
    "    bare_summary = summarize_one_text(review, model_bare)\n",
    "\n",
    "    predictions_tuned.append(fine_tuned_summary)\n",
    "    predictions_bare.append(bare_summary)\n",
    "    targets.append(summary)\n",
    "    texts.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "526e387b",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = iter(range(len(targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "268b1f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions_tuned) == len(predictions_bare) == len(targets) == len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "015529a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Original review**: This is the first cordless hoover I have had and it is lovely not having the wire get in the way and the constant moving of the plug. The charge is ok it's enough to do the whole house. We have got in the habit of charging straight after use or it can be frustrating if you forget and go to Hoover and the batter is dead. It takes a few hours to charge. I have had a couple of issues one with the charger and one with the hoover but I contacted Planet Express and they were extremely helpful and sent replacement parts. This is really important for me knowing if there are problems the company will resolve it and someone will reply to my contact. I would recommend this hoover (**132**)\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Target summary**: The cordless vacuum provides freedom from wires and has a sufficient charge for the whole house. Charging immediately after use is necessary to avoid frustration. The company's excellent customer service resolves any issues promptly. Overall, highly recommended. (**37**)\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Gererated summary**:\n",
       " The cordless hoover is lovely not having the wire get in the way and the constant moving of the plug. The charge is ok it's enough to do the whole house. It takes a few hours to charge. The company has been extremely helpful and sent replacement parts. I would recommend this hoover. (**53**)\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Gererated summary from 'bare' T5**:\n",
       " the hoover takes a few hours to charge and is lovely not having the wire get in the way. the charger is ok it's enough to do the whole house. (**30**)\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = next(index_list)\n",
    "\n",
    "target_sum = targets[i]\n",
    "generated_sum = predictions_tuned[i]\n",
    "review = texts[i]\n",
    "bare_pred = predictions_bare[i]\n",
    "\n",
    "len_original = len(review.split(' '))\n",
    "len_tar_summary = len(target_sum.split(' '))\n",
    "len_gen_summary = len(generated_sum.split(' '))\n",
    "len_gen_summary_bare = len(bare_pred.split(' '))\n",
    "scores = scorer.score(target_sum, generated_sum)\n",
    "\n",
    "printmd(f\"**Original review**: {review} (**{len_original}**)\\n\")\n",
    "printmd(f\"**Target summary**: {target_sum} (**{len_tar_summary}**)\\n\")\n",
    "printmd(f\"**Gererated summary**:\\n {generated_sum} (**{len_gen_summary}**)\\n\")\n",
    "printmd(f\"**Gererated summary from 'bare' T5**:\\n {bare_pred} (**{len_gen_summary_bare}**)\\n\")\n",
    "# printmd(\"Rouge1 F1 score: {0:.2f}\\n\".format(scores['rouge1'].fmeasure))\n",
    "# printmd(\"RougeL F1 score: {0:.2f}\\n\".format(scores['rougeL'].fmeasure))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dad397",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t5demo",
   "language": "python",
   "name": "t5demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
